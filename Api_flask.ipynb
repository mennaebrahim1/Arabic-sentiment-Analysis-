{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\me513\\anaconda3\\envs\\gp\\lib\\site-packages\\keras\\src\\losses.py:2940: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pickle\n",
        "\n",
        "# Load the tokenizer\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\me513\\anaconda3\\envs\\gp\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "class TransformerModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, ff_dim, num_transformer_blocks, output_dim, rate=0.1):\n",
        "        # Call the constructor of the parent class (tf.keras.Model)\n",
        "        super().__init__()  # This line is crucial for proper initialization\n",
        "\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        self.attention = tfa.layers.MultiHeadAttention(head_size=num_heads, num_heads=num_heads)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation='relu'),\n",
        "            layers.Dense(d_model),\n",
        "        ])\n",
        "\n",
        "        self.rnn_layer = layers.GRU(16, return_sequences=True)\n",
        "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "        self.pooling = layers.GlobalAveragePooling1D()\n",
        "        self.dense = layers.Dense(output_dim, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = tf.reshape(x, [-1, tf.shape(x)[1], self.embedding.output_dim])\n",
        "\n",
        "        attention_output = self.attention([x, x, x])\n",
        "        x = x + attention_output\n",
        "        x = self.rnn_layer(x)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = x + attention_output\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.pooling(x)\n",
        "        return self.dense(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\me513\\anaconda3\\envs\\gp\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\me513\\anaconda3\\envs\\gp\\lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "output_dim = 3\n",
        "num_transformer_blocks = 2\n",
        "d_model = 96\n",
        "num_heads = 8\n",
        "ff_dim = 128\n",
        "dropout_rate = 0.1\n",
        "learning_rate = 0.00022491452958964034\n",
        "# Rebuild the model architecture\n",
        "model = TransformerModel(vocab_size, d_model, num_heads, ff_dim, num_transformer_blocks, output_dim, rate=dropout_rate)\n",
        "\n",
        "# Call the model with some dummy data to build its structure\n",
        "dummy_input = tf.random.uniform((1, 10))  # A random tensor with shape (batch_size, input_length)\n",
        "model(dummy_input)  # This will build the model\n",
        "\n",
        "# Now load the weights\n",
        "model.load_weights('transformer_weights.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNOsM9FKSazA",
        "outputId": "a8245440-ad1e-4497-e9c8-32b1c8fbf5db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://192.168.1.2:5000\n",
            "Press CTRL+C to quit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "192.168.1.2 - - [21/Oct/2024 20:25:30] \"POST /predictAPI HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from flask import Flask, request, Response\n",
        "import numpy as np\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "def prediction_test(review_padded):\n",
        "    predictions = model.predict(review_padded)\n",
        "    predicted_classes = predictions.argmax(axis=-1)\n",
        "    predicted_classes = np.vectorize({2: -1, 1: 1, 0: 0}.get)(predicted_classes)\n",
        "    return predicted_classes\n",
        "\n",
        "def respond(review=\" \"):\n",
        "    review_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        tokenizer.texts_to_sequences([review]), maxlen=100, padding='post', truncating='post'\n",
        "    )\n",
        "    pred = prediction_test(review_padded)\n",
        "    return pred\n",
        "\n",
        "@app.route('/predictAPI', methods=['POST'])\n",
        "def create_page():\n",
        "    input_sentence = request.json.get('inputs', \"\")  # Get the input sentence\n",
        "    \n",
        "    if not input_sentence:\n",
        "        return Response(json.dumps({\"error\": \"No input provided\"}), status=400, mimetype='application/json')\n",
        "\n",
        "    predicted = respond(input_sentence)  # Pass the input sentence directly to respond\n",
        "    response_data = {'predicted': predicted}\n",
        "    return Response(json.dumps(response_data, cls=NumpyEncoder), mimetype='application/json')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host='0.0.0.0', port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ9v2WszZbpD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
